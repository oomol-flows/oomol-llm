executor:
  name: python
  options:
    entry: __init__.py
inputs_def:
  - handle: timeout
    json_schema:
      type: number
      minimum: 0
    value: 30
  - handle: retry_times
    json_schema:
      type: integer
      minimum: 0
    value: 0
  - handle: retry_sleep
    json_schema:
      type: number
      minimum: 0
    value: 3.5
  - handle: stream
    json_schema:
      type: boolean
  - handle: model
    json_schema:
      ui:options:
        title: Model
      ui:widget: self::model
    value:
      model: oomol-chat
      temperature: 0
      top_p: 0.5
      max_tokens: 4096
  - handle: template
    json_schema:
      anyOf:
        - type: string
        - type: array
      ui:options:
        title: Prompt
      ui:widget: self::messages
    value:
      - role: user
        content: "{{input}}"
    schema_overrides:
      - schema:
          type: array
outputs_def:
  - handle: output
    json_schema:
      type: string
title: LLM chat
additional_inputs: true
additional_outputs: false
additional_inputs_def:
  - handle: input
    json_schema:
      type: string
