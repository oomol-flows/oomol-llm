nodes:
  - node_id: llm-template#3
    title: "%llm-generate-messages-1%"
    inputs_from:
      - handle: template
        value:
          - role: system
            content: "You should engage in friendly conversations with users. When users ask
              questions, answer them briefly, avoiding verbose answers. You
              should stand firm on your opinions and challenge them. If users
              challenge you, don't just give brief responses; respond with
              detailed evidence."
          - role: user
            content: In which year did Columbus discover the New World?
        schema_overrides:
          - schema:
              type: array
      - handle: messages
        value:
    task: self::messages-generator
    inputs_def:
      []
  - node_id: markdown_text_preview#6
    title: "%markdown-preview-5%"
    inputs_from:
      - handle: text
        from_node:
          - node_id: llm#1
            output_handle: output
    task: oomol-preview::markdown_text_preview
  - node_id: markdown_text_preview#7
    title: "%markdown-preview-6%"
    inputs_from:
      - handle: text
        from_node:
          - node_id: llm-chat#1
            output_handle: output
    task: oomol-preview::markdown_text_preview
  - node_id: llm#1
    title: "%llm-1%"
    inputs_from:
      - handle: messages
        value: null
        from_node:
          - node_id: llm-template#3
            output_handle: messages
      - handle: timeout
        value: 30
      - handle: retry_times
        value: 0
      - handle: retry_sleep
        value: 3.5
      - handle: stream
        value: true
      - handle: model
        value:
          model: deepseek-chat
          temperature: 0.5
          top_p: 1
          max_tokens: 8192
      - handle: template
        value:
          []
        schema_overrides:
          - schema:
              type: array
        from_node:
          []
      - handle: skills
        value:
          []
        schema_overrides:
          - schema:
              type: array
    task: self::llm-json
    inputs_def:
      []
    outputs_def:
      - handle: output
        description: AI's first response to the user's question
        json_schema:
          type: string
  - node_id: llm-chat#1
    title: "%llm-chat-1%"
    inputs_from:
      - handle: messages
        value: null
        from_node:
          - node_id: llm-template#3
            output_handle: messages
      - handle: timeout
        value: 30
      - handle: retry_times
        value: 0
      - handle: retry_sleep
        value: 3.5
      - handle: stream
        value: true
      - handle: model
        value:
          model: deepseek-chat
          temperature: 0.5
          top_p: 1
          max_tokens: 8192
      - handle: template
        value:
          - role: assistant
            content: "{{answer}}\n"
          - role: user
            content: |-
              I think you're wrong? I'll give you 3 seconds to answer again. I want to see a different answer.
        schema_overrides:
          - schema:
              type: array
      - handle: answer
        from_node:
          - node_id: llm#1
            output_handle: output
      - handle: skills
        value:
          []
        schema_overrides:
          - schema:
              type: array
    task: self::llm-chat
    inputs_def:
      - handle: answer
        description: AI's previous answer to be challenged in the follow-up conversation
title: "%chat-with-history%"
description: "%a-demonstration-flow-showing-how-ai-maintains-conversation-conte%"
