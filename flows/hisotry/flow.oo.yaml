nodes:
  - node_id: llm-template#3
    title: "LLM generate messages #1"
    inputs_from:
      - handle: template
        value:
          - role: system
            content: "你要与用户友善地对话。用户问问题，你要简短地回答，不要啰里八嗦。你要坚持自己的观点，敢于挑战用户。若用户质疑，你就不要简短答复了，用详实的\
              证据回应。"
          - role: user
            content: 哥伦布是哪一年发现新大陆的？
        schema_overrides:
          - schema:
              type: array
      - handle: messages
        value:
    task: self::messages-generator
    inputs_def:
      []
  - node_id: llm-messages#1
    title: "LLM generate messages #3"
    inputs_from:
      - handle: template
        value:
          - role: assistant
            content: "{{input}}"
        schema_overrides:
          - schema:
              type: array
        from_node:
          []
      - handle: messages
        value: null
        from_node:
          - node_id: llm-template#3
            output_handle: messages
      - handle: input
        from_node:
          - node_id: llm#1
            output_handle: output
    task: self::messages-generator
    inputs_def:
      - handle: input
        json_schema:
          type: string
        nullable: false
  - node_id: markdown_text_preview#6
    title: "Markdown preview #5"
    inputs_from:
      - handle: text
        from_node:
          - node_id: llm#1
            output_handle: output
    task: oomol-preview::markdown_text_preview
  - node_id: markdown_text_preview#7
    title: "Markdown preview #6"
    inputs_from:
      - handle: text
        from_node:
          - node_id: llm-chat#1
            output_handle: output
    task: oomol-preview::markdown_text_preview
  - node_id: llm#1
    title: "LLM #1"
    inputs_from:
      - handle: messages
        value: null
        from_node:
          - node_id: llm-template#3
            output_handle: messages
      - handle: timeout
        value: 30
      - handle: retry_times
        value: 0
      - handle: retry_sleep
        value: 3.5
      - handle: stream
        value: true
      - handle: model
        value:
          model: oomol-chat
          temperature: 0
          top_p: 0.5
          max_tokens: 4096
      - handle: template
        value:
          []
        schema_overrides:
          - schema:
              type: array
        from_node:
          []
    task: self::llm
    inputs_def:
      []
    outputs_def:
      - handle: output
        description: write your answer here
        json_schema:
          type: string
  - node_id: llm-chat#1
    title: "LLM chat #1"
    inputs_from:
      - handle: messages
        value: null
        from_node:
          - node_id: llm-messages#1
            output_handle: messages
      - handle: timeout
        value: 30
      - handle: retry_times
        value: 0
      - handle: retry_sleep
        value: 3.5
      - handle: stream
        value: true
      - handle: model
        value:
          model: oomol-chat
          temperature: 0
          top_p: 0.5
          max_tokens: 4096
      - handle: template
        value:
          - role: user
            content: "我觉得你说得不对？我给你3秒钟重新回答，我要看到不一样的答案。"
        schema_overrides:
          - schema:
              type: array
    task: self::llm-chat
    inputs_def:
      []
title: Chat with history
